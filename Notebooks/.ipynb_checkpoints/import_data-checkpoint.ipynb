{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Cleaned Data (csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stuff\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import psycopg2.extras\n",
    "\n",
    "# Imports the method used to connect to DBs\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# function to establish a session with a connected database\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "# database compliant datatypes\n",
    "from sqlalchemy import Column, Integer, String, Float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the PostgreSQL engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# password is hard-coded in the connection string as \"postgres\"\n",
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/energy_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear out data first\n",
    "### Start with the fact (dependent) tables first, then drop foreign keys, truncate rest of tables and then re-add keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate non-dependent tables first\n",
    "engine.execute('TRUNCATE TABLE state_greenhouse_emissions;')\n",
    "engine.execute('TRUNCATE TABLE region_degree_days;')\n",
    "engine.execute('TRUNCATE TABLE facility_emissions;')\n",
    "engine.execute('TRUNCATE TABLE air_quality;')\n",
    "engine.execute('TRUNCATE TABLE state_data;')\n",
    "engine.execute('TRUNCATE TABLE state_region;')\n",
    "\n",
    "# list of foreign keys to be dropped so the basic data can be truncated, results of \"foreign_key_list.sql\"\n",
    "#   this is entirely due to lazyness, so we can copy/paste\n",
    "\n",
    "# \"air_quality\"\t\"fk_air_quality_state\"\n",
    "# \"facility_emissions\"\t\"fk_facility_emissions_facility_id\"\n",
    "# \"facility\"\t\"fk_facility_state\"\n",
    "# \"region_degree_days\"\t\"fk_region_degree_days_region\"\n",
    "# \"state_data\"\t\"fk_state_data_state\"\n",
    "# \"state_greenhouse_emissions\"\t\"fk_state_greenhouse_emissions_state\"\n",
    "# \"state_region\"\t\"fk_state_region_region\"\n",
    "# \"state_region\"\t\"fk_state_region_state\"\n",
    "\n",
    "# drop all the foreign keys\n",
    "engine.execute('ALTER TABLE facility DROP CONSTRAINT fk_facility_state;')\n",
    "engine.execute('ALTER TABLE state_region DROP CONSTRAINT fk_state_region_region;')\n",
    "engine.execute('ALTER TABLE state_region DROP CONSTRAINT fk_state_region_state;')\n",
    "engine.execute('ALTER TABLE state_greenhouse_emissions DROP CONSTRAINT fk_state_greenhouse_emissions_state;')\n",
    "engine.execute('ALTER TABLE region_degree_days DROP CONSTRAINT fk_region_degree_days_region;')\n",
    "engine.execute('ALTER TABLE facility_emissions DROP CONSTRAINT fk_facility_emissions_facility_id;')\n",
    "engine.execute('ALTER TABLE air_quality DROP CONSTRAINT fk_air_quality_state;')\n",
    "engine.execute('ALTER TABLE state_data DROP CONSTRAINT fk_state_data_state;')\n",
    "\n",
    "# truncate the rest of the tables\n",
    "engine.execute('TRUNCATE TABLE state;')\n",
    "engine.execute('TRUNCATE TABLE facility;')\n",
    "engine.execute('TRUNCATE TABLE region;')\n",
    "\n",
    "# add the keys back (table names and columns are in the index name, so it's not hard to decode)\n",
    "engine.execute('ALTER TABLE facility ADD CONSTRAINT fk_facility_state FOREIGN KEY (state) REFERENCES state (state);')\n",
    "engine.execute('ALTER TABLE state_region ADD CONSTRAINT fk_state_region_region FOREIGN KEY (region) REFERENCES region (region);')\n",
    "engine.execute('ALTER TABLE state_region ADD CONSTRAINT fk_state_region_state FOREIGN KEY (state) REFERENCES state (state);')\n",
    "engine.execute('ALTER TABLE state_greenhouse_emissions ADD CONSTRAINT fk_state_greenhouse_emissions_state FOREIGN KEY (state) REFERENCES state (state);')\n",
    "engine.execute('ALTER TABLE region_degree_days ADD CONSTRAINT fk_region_degree_days_region FOREIGN KEY (region) REFERENCES region (region);')\n",
    "engine.execute('ALTER TABLE facility_emissions ADD CONSTRAINT fk_facility_emissions_facility_id FOREIGN KEY (facility_id) REFERENCES facility (facility_id);')\n",
    "engine.execute('ALTER TABLE air_quality ADD CONSTRAINT fk_air_quality_state FOREIGN KEY (state) REFERENCES state (state);')\n",
    "engine.execute('ALTER TABLE state_data ADD CONSTRAINT fk_state_data_state FOREIGN KEY (state) REFERENCES state (state);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just making sure tables are empty\n",
    "engine.execute(\"SELECT * FROM state;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the metadata first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import, preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states\n",
    "state_file = os.path.join(\"..\",\"Clean Data Files\",\"state.csv\")\n",
    "state_df = pd.read_csv(state_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "state_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to PostgreSQL, return rows to verify\n",
    "##### Caution, to re-run, you have to run the truncate table code above first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "state_df.to_sql('state', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM state LIMIT 10\").fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### region\n",
    "#### import csv, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states\n",
    "region_file = os.path.join(\"..\",\"Clean Data Files\",\"region.csv\")\n",
    "region_df = pd.read_csv(region_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "region_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write df to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "region_df.to_sql('region', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM region LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state_region\n",
    "#### import csv, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states\n",
    "state_region_file = os.path.join(\"..\",\"Clean Data Files\",\"state_region.csv\")\n",
    "state_region_df = pd.read_csv(state_region_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "state_region_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "state_region_df.to_sql('state_region', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM state_region LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the fun data\n",
    "### faccility first\n",
    "#### import csv, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facility\n",
    "facility_file = os.path.join(\"..\",\"Clean Data Files\",\"facility.csv\")\n",
    "facility_df = pd.read_csv(facility_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "facility_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename colummns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to match database column names\n",
    "facility_df = facility_df.rename(columns={\n",
    "    'facility id':'facility_id', \n",
    "    'frs id': 'frs_id',\n",
    "    'facility name': 'facility_name'\n",
    "})\n",
    "facility_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append to facility table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "facility_df.to_sql('facility', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM facility LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facility emissions\n",
    "#### import csv, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facility emissions\n",
    "facility_emissions_file = os.path.join(\"..\",\"Clean Data Files\",\"facility emissions.csv\")\n",
    "facility_emissions_df = pd.read_csv(facility_emissions_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "facility_emissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to match database column names\n",
    "facility_emissions_df = facility_emissions_df.rename(columns={\n",
    "    'facility id':'facility_id', \n",
    "    'greenhouse emissions': 'emissions_mt'\n",
    "})\n",
    "facility_emissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append to table, update nulls to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "facility_emissions_df.to_sql('facility_emissions', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# update the \"nones\" to zeros so they are all numbers\n",
    "engine.execute(\"UPDATE facility_emissions SET emissions_mt = 0 WHERE emissions_mt IS NULL;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM facility_emissions LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REgion degree days\n",
    "#### import csv, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region degree days\n",
    "region_degree_days_file = os.path.join(\"..\",\"Clean Data Files\",\"region degree days.csv\")\n",
    "region_degree_days_df = pd.read_csv(region_degree_days_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "region_degree_days_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to match database column names\n",
    "region_degree_days_df = region_degree_days_df.rename(columns={\n",
    "    'heating degree days':'heating_degree_days', \n",
    "    'cooling degree days': 'cooling_degree_days'\n",
    "})\n",
    "region_degree_days_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append to table, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "region_degree_days_df.to_sql('region_degree_days', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM region_degree_days LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state greenhouse emissions\n",
    "#### import data and examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region degree days\n",
    "state_greenhouse_emissions_file = os.path.join(\"..\",\"Clean Data Files\",\"state greenhouse emissions.csv\")\n",
    "state_greenhouse_emissions_df = pd.read_csv(state_greenhouse_emissions_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "state_greenhouse_emissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to match database column names\n",
    "state_greenhouse_emissions_df = state_greenhouse_emissions_df.rename(columns={\n",
    "    'greenhouse emissions':'greenhouse_emissions'\n",
    "})\n",
    "state_greenhouse_emissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "state_greenhouse_emissions_df.to_sql('state_greenhouse_emissions', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM state_greenhouse_emissions LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Data!\n",
    "#### Import csv, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region degree days\n",
    "state_data_file = os.path.join(\"..\",\"Clean Data Files\",\"state data.csv\")\n",
    "state_data_df = pd.read_csv(state_data_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "state_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to match database column names\n",
    "state_data_df = state_data_df.rename(columns={\n",
    "    'producer type':'producer_type',\n",
    "    'energy source':'energy_source',\n",
    "    'CO2 (MT)':'co2_mt',\n",
    "    'SO2 (MT)':'so2_mt',\n",
    "    'NOx (MT)':'nox_mt',\n",
    "    'generation (mwh)':'generation_mwh'\n",
    "})\n",
    "\n",
    "# display  \n",
    "state_data_df['state'] = state_data_df['state'].str.upper() \n",
    "  \n",
    "state_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replaced a '.' with a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error on row 9874\n",
    "# replacing a decimal with a zero, it throws a SQL error\n",
    "state_data_df.loc[(state_data_df.consumption == '.'),'consumption']='0'\n",
    "\n",
    "len(state_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separating out the three rows with empty state values \n",
    "Printing out discarded rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to seperate three rows where\n",
    "clean_state_df = state_data_df[state_data_df['state'] != '  ']\n",
    "\n",
    "# what was thrown away...\n",
    "empty_state_df = state_data_df[state_data_df['state'] == '  ']\n",
    "\n",
    "empty_state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append and review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "clean_state_df.to_sql('state_data', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM state_data LIMIT 10\").fetchall()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air quality data\n",
    "#### Import, examine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region degree days\n",
    "air_quality_file = os.path.join(\"final_aqi_df.csv\")\n",
    "air_quality_df = pd.read_csv(air_quality_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# preview the raw data\n",
    "air_quality_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename to match table column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to match database column names\n",
    "air_quality_df = air_quality_df.rename(columns={\n",
    "    'State':'state',\n",
    "    'Year':'year',\n",
    "    'CBSA Code':'cbsa_code',\n",
    "    'Days with AQI': 'days_with_aqi',\n",
    "    'Good Days':'good_days',\n",
    "    'Moderate Days':'moderate_days',\n",
    "    'Unhealthy Days': 'unhealthy_days',\n",
    "    'Unhealthy for Sensitive Groups Days': 'unhealthy_sensitive_days',\n",
    "    'Very Unhealthy Days': 'very_unhealthy_days',\n",
    "    'Hazardous Days': 'hazardous_days',\n",
    "    'Max AQI': 'aqi_max',\n",
    "    '90th Percentile AQI': 'aqi_90_percentile',\n",
    "    'Median AQI': 'aqi_median',\n",
    "    'Days CO': 'days_co',\n",
    "    'Days NO2': 'days_no2',\n",
    "    'Days Ozone': 'days_ozone',\n",
    "    'Days SO2': 'days_so2',\n",
    "    'Days PM2.5': 'days_pm25',\n",
    "    'Days PM10': 'days_pm10'\n",
    "})\n",
    "\n",
    "air_quality_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to table, replace the rows if they exist\n",
    "air_quality_df.to_sql('air_quality', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# return the data to make sure it was appended correctly\n",
    "engine.execute(\"SELECT * FROM air_quality LIMIT 10\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
